
<컴퓨터에서의 문자표현>
글자 'A'를 메모리에 저장하는 방법
- 메모리는 숫자만을 저장할 수 있어서 각 문자에 대응되는 숫자를 규칙으로 정해놓고, 이것을 메모리에 저장하는 방법이 사용됨.
- 영어의 경우 대소문자가 총 52개 이므로 6비트(64가지)면 이 모두를 포현할 수 있음
ex) 000000 -> 'a', 00001 -> 'b'

<표준 ASCII(American Standard Code ofr Information Interchange)>
- 문자 인코딩 표준
- 네트워크가 발전되기 전 미국의 각 지역별로 코드체계를 정해놓고 사용했지만, 네트워크가 발전하면서
  서로 간의 정보를 주고받을 때 정보를 달리 해석하게되는 문제가 발생하여 미국에서 만들어진 코드체계.
- 7bit 인코딩으로 128문자를 표현(33개의 출력 불가능한 제어 문자들, 공백을 비롯한 95개의 출력 가능한 문자)

<확장 ASCII>
- ASCII가 7bit만을 사용하는 반면 확장 ASCII는 1Byte 내의 8bit를 모두 사용함으로써 추가적인 문자를 표현할 수 있음.
- 표준문자 이외의 악센트 문자, 도형 문자, 특수 문자, 특수 기호 등 부가적인 128개의 문자를 추가할 수 있게 하는 부호
- 프로그램이나 하드웨어가 이것을 해독할 수 있도록 설계되어 있어야만 올바르게 해독될 수 있다.
- 이 이유로 컴퓨터 생산자와 소프트웨어 개발자에게 할당된 확장 부호는 표준 아스키와 다르게 서로 다른 프로그램이나 컴퓨터 사이에 교환되지는 못함.

<유니코드>
- 다국어 처리를 위한 표준
- ASCII가 만들어진 이유와 거의 비슷함.
- 원래 대부분의 컴퓨터는 문자를 읽고 쓰는데 ASCII 코드 형식을 사용했는데
- 컴퓨터가 점차 발전하면서 각 국가들은 자국의 문자를 표현하기 위하여 따로 코드체계를 만들어 사용하였는데 국가간 소통의 문제로 유니코드가 만들어졌음.
- 유니코드를 저장하는 변수의 크기에 따라 두 개의 Character Set으로 분류됨.
- UCS-2(Universal Character Set 2)
- UCS-4(Universal Character Set 4)
- 유니코드의 바이트 순서를 정의하는 인코딩이 '유니코드 인코딩'
- 유니코드 인코딩 : UTF(Unicode Transformation Format)
- 바이트 용량의 최소값에 따라 UTF-8, UTF-16, UTF-32 등 으로 나뉘어 짐
UTF-8 : Web에서 사용             | MIN : 8bit  | MAX : 32bit(1Byte * 4)
UTF-16 : Windows, Java에서 사용  | MIN : 16bit | MAX : 32bit(2Byte * 2)
UTF-32 : Unix에서 사용           | MIN : 32bit | MAX : 32bit(4Byte * 1)
- Python에서의 인코딩 방식은
2.x 버전 - ASCII (코드에 한글 사용불가) => #-*-coding: utf-8-*- 형태로 상단에 명시하여 인코딩 방식을 바꿔주면 한글 사용가능
3.x 버전 - UTF-8

<문자열의 분류>
                |String|

|Fixed length|            |Variable length|

              |Length controlled|     |Delimited|

문자열(String) - 고정길이 문자열(Fixed length String), 가변길이 문자열(Variable length String)

고정길이 문자열 : 문자열의 길이가 고정되어 있는 문자열
가변길이 문자열 : 문자열의 길이가 변할 수 있는 문자열

가변길이 문자열 - 길이조절 문자열(Length controlled String), 구분자 문자열(Delimited String)

길이조절 문자열 : JAVA에서 자주 쓰이는 문자열로 문자열 데이터 맨앞에 문자열의 길이를 저장하는 형태로 문자열을 저장.
구분자 문자열 : C언어에서 자주 쓰이는 문자열로 딜리미터라는 문자열 구분자를 이용하여 문자열의 길이를 조절함.

<각 언어에서의 문자열 처리>
C 언어      - 아스키 코드로 저장
             ex) "홍길동" 에 대해 strlen을 하면 6출력 -> ASCII문자의 경우 한글자가 1byte이고, 한글문자 하나가 2byte로 인식됨
           - 문자배열에 문자열을 저장할 때는 항상 마지막에 끝을 표시하는 null문자('\0')를 넣어줘야 한다.
             ex) char arr[] = {'a', 'b', 'c', '\0'} 또는 char arr[] = "abc"

Java 언어   - 유니코드(UTF-16)로 저장
             ex) "홍길동" 에 대해 length를 하면 3출력 -> 2byte 단위로 문자 하나를 인식
           - String 클래스를 사용
             ex) String str = "abc" 또는 String str = new String("abc")

Python 언어 - 유니코드(UTF-8)로 저장
             ex) "홍길동" 에 대해 len을 하면 3출력 ->
           - char 타입이 존재하지 않고, 텍스트 데이터 취급방법이 통일되어 있다.
           - 문자열은 시퀀스 자료형으로 분류되고, 인덱싱, 슬라이싱 연산들을 사용할 수 있다.
           - 문자열은 튜플과 같아서 요소의 값을 인덱스로 접근하여 변경 할 수 없다.
           - 문자열 메소드 중 값을 변경하는 메소드는 원본 문자열을 수정하는 것을 아니라 변경된 새로운 문자열을 만들어 반환해주는 것이다.
